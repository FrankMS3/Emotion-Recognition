{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing os module\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_array(emotion):\n",
    "    #first_two = emotion[0:2]\n",
    "    x = []\n",
    "    y = []\n",
    "    #x.append([])\n",
    "    #x[0].append([])\n",
    "    folder = \"C:/Users/User/Project 4 local/archive/\"+emotion\n",
    "    for count, filename in enumerate(os.listdir(folder)):\n",
    "        # load the image\n",
    "        img = Image.open(f\"{folder}/{filename}\")\n",
    "        # asarray() class is used to convert\n",
    "        # PIL images into NumPy arrays\n",
    "        img_data = asarray(img)\n",
    "        #img_data = img_data.reshape(-1,1)\n",
    "        #np.append(X, img_data,axis=0)\n",
    "        x.append(img_data)\n",
    "        y.append(filename[0:2])\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature1,target1 = img_to_array(\"anger\")\n",
    "feature2,target2 = img_to_array(\"contempt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1098"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature = feature1 + feature2\n",
    "len(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_arr = np.array(feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1098, 224, 224)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1098,)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = target1 + target2\n",
    "target_arr = np.array(target)\n",
    "target_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_arr\n",
    "y= target_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn to split dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(823, 224, 224)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(823,)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[21, 21, 21, ..., 45, 45, 45],\n",
       "       [21, 21, 21, ..., 45, 45, 45],\n",
       "       [22, 22, 22, ..., 19, 19, 19],\n",
       "       ...,\n",
       "       [ 9,  9,  9, ...,  1,  1,  1],\n",
       "       [ 7,  7,  7, ...,  1,  1,  1],\n",
       "       [ 7,  7,  7, ...,  1,  1,  1]], dtype=uint8)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Shape: (823, 50176)\n",
      "Testing Shape: (275, 50176)\n"
     ]
    }
   ],
   "source": [
    "# We want to flatten our image of 28x28 pixels to a 1D array of 784 pixels\n",
    "ndims = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], ndims)\n",
    "X_test = X_test.reshape(X_test.shape[0], ndims)\n",
    "print(\"Training Shape:\", X_train.shape)\n",
    "print(\"Testing Shape:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies to Visualise the model\n",
    "%matplotlib inline\n",
    "from IPython.display import Image, SVG\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import tensorflow as tf\n",
    "# Sklearn scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "tf.config.run_functions_eagerly(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we normalise our training data to be between 0 and 1\n",
    "scaler = MinMaxScaler().fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['an', 'an', 'an', 'an', 'an', 'an', 'co', 'an', 'co', 'an', 'an',\n",
       "       'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an',\n",
       "       'an', 'an', 'an', 'co', 'an', 'an', 'an', 'an', 'an', 'an', 'an',\n",
       "       'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an',\n",
       "       'co', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'co', 'an', 'co',\n",
       "       'co', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an',\n",
       "       'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'co', 'co',\n",
       "       'an', 'co', 'an', 'an', 'an', 'co', 'an', 'co', 'an', 'an', 'co',\n",
       "       'an', 'an', 'an', 'an', 'an', 'an', 'an', 'co', 'an', 'an', 'an',\n",
       "       'co', 'an', 'an', 'an', 'an', 'co', 'co', 'an', 'an', 'an', 'an',\n",
       "       'an', 'an', 'an', 'an', 'an', 'an', 'co', 'an', 'an', 'an', 'an',\n",
       "       'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'an',\n",
       "       'an', 'an', 'an', 'an', 'an', 'co', 'an', 'co', 'co', 'an', 'an',\n",
       "       'an', 'an', 'an', 'co', 'an', 'an', 'co', 'an', 'an', 'co', 'co',\n",
       "       'an', 'co', 'co', 'an', 'an', 'an', 'an', 'an', 'co', 'an', 'an',\n",
       "       'an', 'an', 'co', 'an', 'co', 'co', 'an', 'an', 'co', 'an', 'an',\n",
       "       'co', 'an', 'an', 'an', 'an', 'an', 'an', 'an', 'co', 'an', 'an',\n",
       "       'an', 'an', 'an', 'co', 'an', 'an', 'co', 'an', 'an', 'an', 'an',\n",
       "       'an', 'an'], dtype='<U2')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_reshaped = y_train.reshape(-1, 1) \n",
    "# y_test_reshaped = y_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "# cat = OneHotEncoder()\n",
    "# y_train_t = y_train_reshaped.T\n",
    "# y_test_t = y_test_reshaped.T\n",
    "# y_train_cat = cat.fit_transform(y_train_t).toarray()\n",
    "# y_test_cat = cat.fit_transform(y_test_t).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train_encoded = le.fit_transform(y_train)\n",
    "y_test_encoded = le.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0.], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to convert our target labels (expected values) to categorical data\n",
    "num_classes = 2\n",
    "y_train_cat = to_categorical(y_train_encoded, num_classes)\n",
    "y_test_cat = to_categorical(y_test_encoded, num_classes)\n",
    "# Original label of `5` is one-hot encoded as `0000010000`\n",
    "y_train_cat[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(823, 50176)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty sequential model\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the first layer where the input dimensions are the 784 pixel values\n",
    "# We can also choose our activation function. `relu` is a common\n",
    "model.add(Dense(100, activation='relu', input_dim=X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a second hidden layer\n",
    "model.add(Dense(100, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add our final output layer where the number of nodes \n",
    "# corresponds to the number of y labels\n",
    "model.add(Dense(2, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 100)               5017700   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 100)               10100     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 202       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,028,002\n",
      "Trainable params: 5,028,002\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We can summarise our model\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use categorical crossentropy for categorical data and mean squared error for regression\n",
    "# Hint: your output layer in this example is using software for logistic regression (categorical)\n",
    "# If your output layer activation was `linear` then you may want to use `mse` for loss\n",
    "model.compile(optimizer='adam', \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\anaconda3\\envs\\PythonData\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:257: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n",
      "  \"Even though the `tf.config.experimental_run_functions_eagerly` \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "26/26 - 6s - loss: 3.6247 - accuracy: 0.6987 - 6s/epoch - 225ms/step\n",
      "Epoch 2/10\n",
      "26/26 - 5s - loss: 1.5104 - accuracy: 0.6841 - 5s/epoch - 203ms/step\n",
      "Epoch 3/10\n",
      "26/26 - 5s - loss: 2.3032 - accuracy: 0.6768 - 5s/epoch - 211ms/step\n",
      "Epoch 4/10\n",
      "26/26 - 5s - loss: 1.1328 - accuracy: 0.7193 - 5s/epoch - 199ms/step\n",
      "Epoch 5/10\n",
      "26/26 - 5s - loss: 0.8709 - accuracy: 0.7254 - 5s/epoch - 207ms/step\n",
      "Epoch 6/10\n",
      "26/26 - 7s - loss: 0.4919 - accuracy: 0.8068 - 7s/epoch - 260ms/step\n",
      "Epoch 7/10\n",
      "26/26 - 6s - loss: 0.7405 - accuracy: 0.7242 - 6s/epoch - 246ms/step\n",
      "Epoch 8/10\n",
      "26/26 - 7s - loss: 0.6000 - accuracy: 0.7655 - 7s/epoch - 252ms/step\n",
      "Epoch 9/10\n",
      "26/26 - 7s - loss: 0.4529 - accuracy: 0.7910 - 7s/epoch - 264ms/step\n",
      "Epoch 10/10\n",
      "26/26 - 6s - loss: 0.4549 - accuracy: 0.8032 - 6s/epoch - 239ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2509eb958c8>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit (train) the model\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train_cat,\n",
    "    epochs=10,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9da66beca27f19bdf81de16e0121a30aa04d4edd5eb88e9a5610932102b72b6f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
